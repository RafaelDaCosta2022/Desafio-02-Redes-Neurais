import numpy as np
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# Carregar o CSV
base_dados = pd.read_csv('/content/frutas_vegetais_nutrientes-_255.csv')

# Definir df_enum
df_enum = base_dados.copy()

# Limpar os nomes das colunas
df_enum.columns = df_enum.columns.str.strip()

# Verificar se a coluna 'Classificação' existe e criar dados e alvo
if 'Classificação' in df_enum.columns:
    dados = df_enum.drop(columns=['Classificação'])
    alvo = df_enum['Classificação']

    # Codificando a variável alvo
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(alvo)

    # Selecionar apenas colunas numéricas
    dados = dados.select_dtypes(include=[np.number])  # Mantém apenas colunas numéricas

    # Normalizar os dados
    scaler = MinMaxScaler(feature_range=(-1, 1))
    dados = scaler.fit_transform(dados)

    # Dividir os dados em conjuntos de treino e teste
    x_train, x_test, y_train, y_test = train_test_split(dados, y_encoded, test_size=0.10, random_state=42)

    # Criar o modelo de rede neural
    model = tf.keras.models.Sequential([
        tf.keras.layers.Input(shape=(x_train.shape[1],)),  # Define a entrada
        tf.keras.layers.Dense(36, activation='relu'),
        tf.keras.layers.Dense(16, activation='relu'),
        tf.keras.layers.Dense(8, activation='relu'),
        tf.keras.layers.Dense(len(np.unique(y_encoded)), activation='softmax')  # Ajuste para o número de classes
    ])

    # Compilar o modelo
    model.compile(optimizer=tf.keras.optimizers.Adam(),
                  loss='sparse_categorical_crossentropy',  # Para codificação de classes
                  metrics=['accuracy'])  # Use accuracy para problemas de classificação

    # Resumo do modelo
    model.summary()

    # Configuração do EarlyStopping
    early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)

    # Treinar o modelo
    history = model.fit(x_train, y_train, epochs=200, callbacks=[early_stopping], validation_split=0.1)

    # Avaliar o modelo
    loss, accuracy = model.evaluate(x_test, y_test)
    print(f"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}")

    # Gráfico de precisão de treinamento
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.title('Training and Validation Accuracy')

    # Gráfico de perda
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Training and Validation Loss')

    plt.tight_layout()
    plt.show()

else:
    print("A coluna 'Classificação' não existe em df_enum.")
